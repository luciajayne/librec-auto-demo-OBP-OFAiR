<study>
  <completed_at>2022-05-09 09:47:51.315481</completed_at>
  <experiment_count>4</experiment_count>
  <check>
    <message>No errors found in configuration file syntax.</message>
    <message src="librec-auto-demo2021-main/demo01/exp00000/log/librec-20220509_094554.log">No errors found in experiment 0 log.</message>
    <message src="librec-auto-demo2021-main/demo01/exp00001/log/librec-20220509_094556.log">No errors found in experiment 1 log.</message>
    <message src="librec-auto-demo2021-main/demo01/exp00002/log/librec-20220509_094557.log">No errors found in experiment 2 log.</message>
    <message src="librec-auto-demo2021-main/demo01/exp00003/log/librec-20220509_094558.log">No errors found in experiment 3 log.</message>
    <message>No warnings found in log</message>
  </check>
  <experiments>
    <experiment count="0">
      <!--DO NOT EDIT. File automatically generated by librec-auto-->
      <meta>
        <param>
          <name>item-reg</name>
          <value>0.001</value>
        </param>
        <param>
          <name>lambda</name>
          <value>0.0</value>
        </param>
      </meta>
      <results>
        <folds>
          <cv id="1">
            <metric name="NormalizedDCGEvaluator">0.11046540302569002</metric>
            <metric name="PrecisionEvaluator">0.09862646566164106</metric>
            <metric name="PStatisticalParityEvaluator">0.35350083752093897</metric>
          </cv>
          <cv id="2">
            <metric name="NormalizedDCGEvaluator">0.09796001951369264</metric>
            <metric name="PrecisionEvaluator">0.09621567314132545</metric>
            <metric name="PStatisticalParityEvaluator">0.5135967849966467</metric>
          </cv>
          <cv id="3">
            <metric name="NormalizedDCGEvaluator">0.08071291157173699</metric>
            <metric name="PrecisionEvaluator">0.08356210244392252</metric>
            <metric name="PStatisticalParityEvaluator">0.4620689655172451</metric>
          </cv>
        </folds>
        <averages>
          <metric name="NormalizedDCGEvaluator">0.09637944470370656</metric>
          <metric name="PrecisionEvaluator">0.09280141374896302</metric>
          <metric name="PStatisticalParityEvaluator">0.44305552934494363</metric>
        </averages>
      </results>
    </experiment>
    <experiment count="1">
      <!--DO NOT EDIT. File automatically generated by librec-auto-->
      <meta>
        <param>
          <name>item-reg</name>
          <value>0.01</value>
        </param>
        <param>
          <name>lambda</name>
          <value>0.0</value>
        </param>
      </meta>
      <results>
        <folds>
          <cv id="1">
            <metric name="NormalizedDCGEvaluator">0.09164894477936703</metric>
            <metric name="PrecisionEvaluator">0.08767169179229378</metric>
            <metric name="PStatisticalParityEvaluator">0.31021775544388985</metric>
          </cv>
          <cv id="2">
            <metric name="NormalizedDCGEvaluator">0.08021388850464853</metric>
            <metric name="PrecisionEvaluator">0.08439383791024657</metric>
            <metric name="PStatisticalParityEvaluator">0.5584728734092408</metric>
          </cv>
          <cv id="3">
            <metric name="NormalizedDCGEvaluator">0.06387517258734264</metric>
            <metric name="PrecisionEvaluator">0.07154335453632302</metric>
            <metric name="PStatisticalParityEvaluator">0.45865416806160964</metric>
          </cv>
        </folds>
        <averages>
          <metric name="NormalizedDCGEvaluator">0.07857933529045273</metric>
          <metric name="PrecisionEvaluator">0.08120296141295445</metric>
          <metric name="PStatisticalParityEvaluator">0.44244826563824674</metric>
        </averages>
      </results>
    </experiment>
    <experiment count="2">
      <!--DO NOT EDIT. File automatically generated by librec-auto-->
      <meta>
        <param>
          <name>item-reg</name>
          <value>0.001</value>
        </param>
        <param>
          <name>lambda</name>
          <value>0.3</value>
        </param>
      </meta>
      <results>
        <folds>
          <cv id="1">
            <metric name="NormalizedDCGEvaluator">0.11414021459905124</metric>
            <metric name="PrecisionEvaluator">0.10184254606365109</metric>
            <metric name="PStatisticalParityEvaluator">0.262914572864321</metric>
          </cv>
          <cv id="2">
            <metric name="NormalizedDCGEvaluator">0.10180708252600115</metric>
            <metric name="PrecisionEvaluator">0.09996651038178125</metric>
            <metric name="PStatisticalParityEvaluator">0.36878767582050076</metric>
          </cv>
          <cv id="3">
            <metric name="NormalizedDCGEvaluator">0.08528768643866448</metric>
            <metric name="PrecisionEvaluator">0.08761298962169299</metric>
            <metric name="PStatisticalParityEvaluator">0.3148978908604045</metric>
          </cv>
        </folds>
        <averages>
          <metric name="NormalizedDCGEvaluator">0.10041166118790562</metric>
          <metric name="PrecisionEvaluator">0.09647401535570845</metric>
          <metric name="PStatisticalParityEvaluator">0.3155333798484088</metric>
        </averages>
      </results>
    </experiment>
    <experiment count="3">
      <!--DO NOT EDIT. File automatically generated by librec-auto-->
      <meta>
        <param>
          <name>item-reg</name>
          <value>0.01</value>
        </param>
        <param>
          <name>lambda</name>
          <value>0.3</value>
        </param>
      </meta>
      <results>
        <folds>
          <cv id="1">
            <metric name="NormalizedDCGEvaluator">0.09448046615473164</metric>
            <metric name="PrecisionEvaluator">0.0902847571189271</metric>
            <metric name="PStatisticalParityEvaluator">0.25628140703517555</metric>
          </cv>
          <cv id="2">
            <metric name="NormalizedDCGEvaluator">0.08260575163197459</metric>
            <metric name="PrecisionEvaluator">0.08593436034829066</metric>
            <metric name="PStatisticalParityEvaluator">0.3942397856664469</metric>
          </cv>
          <cv id="3">
            <metric name="NormalizedDCGEvaluator">0.06790283425250426</metric>
            <metric name="PrecisionEvaluator">0.07482423836625263</metric>
            <metric name="PStatisticalParityEvaluator">0.32654837629729855</metric>
          </cv>
        </folds>
        <averages>
          <metric name="NormalizedDCGEvaluator">0.08166301734640351</metric>
          <metric name="PrecisionEvaluator">0.08368111861115679</metric>
          <metric name="PStatisticalParityEvaluator">0.3256898563329737</metric>
        </averages>
      </results>
    </experiment>
  </experiments>
  <config>
    <random-seed>202110</random-seed>
    <!-- This is the configuration used to run the study. -->
    <thread-count>1</thread-count>
    <library src="system">default-algorithms.xml</library>
    <!-- DATA SECTION -->
    <data>
      <data-dir>../data</data-dir>
      <format>UIR</format>
      <data-file format="text">ratings.csv</data-file>
    </data>
    <!-- FEATURES SECTION -->
    <features>
      <appender-class>net.librec.data.convertor.appender.ItemFeatureAppender</appender-class>
      <item-feature-file>item-features.csv</item-feature-file>
      <protected-feature name="fea:new" type="item">new</protected-feature>
    </features>
    <!-- SPLITTER SECTION -->
    <splitter>
      <model count="3">kcv</model>
      <save>true</save>
    </splitter>
    <!-- ALGORITHM SECTION -->
    <!-- Using biased matrix factorization just for demonstration purposes. -->
    <!-- See default-library.xml file for different LibRec algorithms and their parameters -->
    <alg ref="alg:biasedmf">
      <similarity type="item">cos</similarity>
      <iterator-max>25</iterator-max>
      <!-- Way too few iterations to be meaningful -->
      <item-reg>
        <value>0.001</value>
        <value>0.01</value>
      </item-reg>
      <num-factors>20</num-factors>
    </alg>
    <!-- RERANK SECTION -->
    <rerank>
      <script lang="python3" src="system">
        <script-name>far_rerank.py</script-name>
        <param name="max_len">10</param>
        <param name="lambda">
          <value>0.0</value>
          <value>0.3</value>
        </param>
        <param name="binary">False</param>
        <param ref="fea:new"/>
      </script>
    </rerank>
    <!-- METRICS SECTION -->
    <metric>
      <ranking>true</ranking>
      <list-size>50</list-size>
      <class>ndcg,precision,psp</class>
      <protected-feature ref="fea:new"/>
    </metric>
    <!-- POST-PROCESSING SECTION -->
    <post>
      <script lang="python3" src="system">
        <script-name>result_graphics.py</script-name>
        <param name="browser">true</param>
      </script>
    </post>
  </config>
</study>
