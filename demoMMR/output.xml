<study>
  <completed_at>2022-04-25 12:30:59.713498</completed_at>
  <experiment_count>4</experiment_count>
  <check>
    <message>No errors found in configuration file syntax.</message>
    <message src="librec-auto-demo2021-main\demoMMR\exp00000\log\librec-20220425_122809.log">No errors found in experiment 0 log.</message>
    <message src="librec-auto-demo2021-main\demoMMR\exp00001\log\librec-20220425_122810.log">No errors found in experiment 1 log.</message>
    <message src="librec-auto-demo2021-main\demoMMR\exp00002\log\librec-20220425_122811.log">No errors found in experiment 2 log.</message>
    <message src="librec-auto-demo2021-main\demoMMR\exp00003\log\librec-20220425_122813.log">No errors found in experiment 3 log.</message>
    <message src="librec-auto-demo2021-main\demoMMR\LibRec-Auto_log20220425_122808.log">ERROR:root: Script failure: expected_exposure_metric.py: Script at D:\pycharm\bigdata\vbigdata\lib\site-packages\librec_auto-0.2.13-py3.7.egg\librec_auto\core\cmd\eval\expected_exposure_metric.py failed with errors</message>
  </check>
  <experiments>
    <experiment count="0">
      <!--DO NOT EDIT. File automatically generated by librec-auto-->
      <meta>
        <param>
          <name>lambda</name>
          <value>0.93</value>
        </param>
      </meta>
      <results>
        <folds>
          <cv id="1">
            <metric name="NormalizedDCGEvaluator">7.119163978634199E-5</metric>
            <metric name="PrecisionEvaluator">1.5037593984962408E-4</metric>
            <metric name="PStatisticalParityEvaluator">0.10105263157894762</metric>
            <metric name="expected_exposure_metric.py">1.3591848306411576</metric>
            <metric name="ndcg_metric.py">3.816519579069771e-06</metric>
          </cv>
          <cv id="2">
            <metric name="NormalizedDCGEvaluator">2.964313238033393E-4</metric>
            <metric name="PrecisionEvaluator">4.4977511244377816E-4</metric>
            <metric name="PStatisticalParityEvaluator">0.2002998500749611</metric>
            <metric name="expected_exposure_metric.py">1.1928785985831518</metric>
            <metric name="ndcg_metric.py">4.7566282992694003e-07</metric>
          </cv>
          <cv id="3">
            <metric name="NormalizedDCGEvaluator">4.3246899999561006E-4</metric>
            <metric name="PrecisionEvaluator">7.496251874062968E-4</metric>
            <metric name="PStatisticalParityEvaluator">0.23268365817091258</metric>
            <metric name="expected_exposure_metric.py">1.217502276743031</metric>
            <metric name="ndcg_metric.py">2.711069004142568e-06</metric>
          </cv>
        </folds>
        <averages>
          <metric name="NormalizedDCGEvaluator">0.00026669732119509714</metric>
          <metric name="PrecisionEvaluator">0.00044992541323323295</metric>
          <metric name="PStatisticalParityEvaluator">0.17801204660827374</metric>
          <metric name="expected_exposure_metric.py">1.2565219019891136</metric>
          <metric name="ndcg_metric.py">2.3344171377130927e-06</metric>
        </averages>
      </results>
    </experiment>
    <experiment count="1">
      <!--DO NOT EDIT. File automatically generated by librec-auto-->
      <meta>
        <param>
          <name>lambda</name>
          <value>0.9</value>
        </param>
      </meta>
      <results>
        <folds>
          <cv id="1"/>
        </folds>
        <averages/>
      </results>
    </experiment>
    <experiment count="2">
      <!--DO NOT EDIT. File automatically generated by librec-auto-->
      <meta>
        <param>
          <name>lambda</name>
          <value>0.87</value>
        </param>
      </meta>
      <results>
        <folds>
          <cv id="1"/>
        </folds>
        <averages/>
      </results>
    </experiment>
    <experiment count="3">
      <!--DO NOT EDIT. File automatically generated by librec-auto-->
      <meta>
        <param>
          <name>lambda</name>
          <value>0.85</value>
        </param>
      </meta>
      <results>
        <folds>
          <cv id="1">
            <metric name="NormalizedDCGEvaluator">7.119163978634199E-5</metric>
            <metric name="PrecisionEvaluator">1.5037593984962408E-4</metric>
            <metric name="PStatisticalParityEvaluator">0.10105263157894762</metric>
          </cv>
          <cv id="2">
            <metric name="NormalizedDCGEvaluator">2.964313238033393E-4</metric>
            <metric name="PrecisionEvaluator">4.4977511244377816E-4</metric>
            <metric name="PStatisticalParityEvaluator">0.2002998500749611</metric>
          </cv>
          <cv id="3">
            <metric name="NormalizedDCGEvaluator">4.3246899999561006E-4</metric>
            <metric name="PrecisionEvaluator">7.496251874062968E-4</metric>
            <metric name="PStatisticalParityEvaluator">0.23268365817091258</metric>
          </cv>
        </folds>
        <averages>
          <metric name="NormalizedDCGEvaluator">0.00026669732119509714</metric>
          <metric name="PrecisionEvaluator">0.00044992541323323295</metric>
          <metric name="PStatisticalParityEvaluator">0.17801204660827374</metric>
        </averages>
      </results>
    </experiment>
  </experiments>
  <config>
    <random-seed>202110</random-seed>
    <!-- This is the configuration used to run the study. -->
    <thread-count>1</thread-count>
    <library src="system">default-algorithms.xml</library>
    <!-- DATA SECTION -->
    <data>
      <data-dir>../dataOFAiR</data-dir>
      <format>UIR</format>
      <data-file format="text">ratings.csv</data-file>
    </data>
    <!-- FEATURES SECTION -->
    <features>
      <appender-class>net.librec.data.convertor.appender.ItemFeatureAppender</appender-class>
      <item-feature-file>item-features.csv</item-feature-file>
      <protected-feature name="fea:new" type="item">new</protected-feature>
    </features>
    <!-- SPLITTER SECTION -->
    <splitter>
      <model count="3">kcv</model>
      <save>true</save>
    </splitter>
    <!-- ALGORITHM SECTION -->
    <!-- Using biased matrix factorization just for demonstration purposes. -->
    <!-- See default-library.xml file for different LibRec algorithms and their parameters -->
    <alg name="alg:nmf">
      <class>nmf</class>
      <iterator-max>10</iterator-max>
      <num-factors>20</num-factors>
      <early-stop>true</early-stop>
    </alg>
    <!-- RERANK SECTION -->
    <rerank>
      <script lang="python3" src="system">
        <script-name>mmr_rerank.py</script-name>
        <param name="max_len">10</param>
        <param name="lambda">
          <value>0.93</value>
          <value>0.9</value>
          <value>0.87</value>
          <value>0.85</value>
        </param>
        <param name="binary">False</param>
        <param ref="fea:new"/>
      </script>
    </rerank>
    <!-- METRICS SECTION -->
    <metric>
      <ranking>true</ranking>
      <list-size>10</list-size>
      <class>ndcg,precision,psp</class>
      <protected-feature ref="fea:new"/>
      <script lang="python3" src="system">
        <script-name>expected_exposure_metric.py</script-name>
      </script>
      <script lang="python3" src="system">
        <script-name>ndcg_metric.py</script-name>
        <param name="list_size">10</param>
      </script>
    </metric>
    <!-- POST-PROCESSING SECTION -->
    <post>
      <script lang="python3" src="system">
        <script-name>result_graphics.py</script-name>
        <param name="browser">true</param>
      </script>
    </post>
  </config>
</study>
